{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "import Packages.ClusteringHelper as ch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "        documents   tokens       indexes  word_indexes mentions  \\\n0               0       EU        (0, 2)             0            \n1               0  rejects       (3, 10)             1            \n2               0   German      (11, 17)             2   German   \n3               0     call      (18, 22)             3            \n4               0       to      (23, 25)             4            \n...           ...      ...           ...           ...      ...   \n285584       1392  younger  (1342, 1349)           265            \n285585       1392  brother  (1350, 1357)           266            \n285586       1392        ,  (1358, 1359)           267            \n285587       1392    Bobby  (1360, 1365)           268    Bobby   \n285588       1392        .  (1366, 1367)           269            \n\n              entities                                    wikidatas  \\\n0                                                                     \n1                                                                     \n2              Germany         http://en.wikipedia.org/wiki/Germany   \n3                                                                     \n4                                                                     \n...                ...                                          ...   \n285584                                                                \n285585                                                                \n285586                                                                \n285587  Bobby_Charlton  http://en.wikipedia.org/wiki/Bobby_Charlton   \n285588                                                                \n\n       numeric_codes alpha_codes  \n0                                 \n1                                 \n2              11867    /m/0345h  \n3                                 \n4                                 \n...              ...         ...  \n285584                            \n285585                            \n285586                            \n285587          4224    /m/01c8x  \n285588                            \n\n[285589 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>documents</th>\n      <th>tokens</th>\n      <th>indexes</th>\n      <th>word_indexes</th>\n      <th>mentions</th>\n      <th>entities</th>\n      <th>wikidatas</th>\n      <th>numeric_codes</th>\n      <th>alpha_codes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>EU</td>\n      <td>(0, 2)</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>rejects</td>\n      <td>(3, 10)</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>German</td>\n      <td>(11, 17)</td>\n      <td>2</td>\n      <td>German</td>\n      <td>Germany</td>\n      <td>http://en.wikipedia.org/wiki/Germany</td>\n      <td>11867</td>\n      <td>/m/0345h</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>call</td>\n      <td>(18, 22)</td>\n      <td>3</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>to</td>\n      <td>(23, 25)</td>\n      <td>4</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>285584</th>\n      <td>1392</td>\n      <td>younger</td>\n      <td>(1342, 1349)</td>\n      <td>265</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>285585</th>\n      <td>1392</td>\n      <td>brother</td>\n      <td>(1350, 1357)</td>\n      <td>266</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>285586</th>\n      <td>1392</td>\n      <td>,</td>\n      <td>(1358, 1359)</td>\n      <td>267</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>285587</th>\n      <td>1392</td>\n      <td>Bobby</td>\n      <td>(1360, 1365)</td>\n      <td>268</td>\n      <td>Bobby</td>\n      <td>Bobby_Charlton</td>\n      <td>http://en.wikipedia.org/wiki/Bobby_Charlton</td>\n      <td>4224</td>\n      <td>/m/01c8x</td>\n    </tr>\n    <tr>\n      <th>285588</th>\n      <td>1392</td>\n      <td>.</td>\n      <td>(1366, 1367)</td>\n      <td>269</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>285589 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, data = ch.read_aida_yago_conll(\n",
    "    \"D:\\\\Sgmon\\\\Documents\\\\Magistrale\\\\TESI\\\\ClusteringAndLinking\\\\aida-yago2-dataset\\\\AIDA-YAGO2-dataset.tsv\")\n",
    "save = False\n",
    "if save:\n",
    "    text_file = open('text.txt', 'w')\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "ents_data = data[data['entities'] != ''].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_train = Path(\n",
    "    \"D:\\\\Sgmon\\\\Documents\\\\Magistrale\\\\TESI\\\\ClusteringAndLinking\\\\aida-yago2-dataset\\\\encodings\\\\AIDA-YAGO2_train_encodings.jsonl\")\n",
    "path_testa = Path(\n",
    "    \"D:\\\\Sgmon\\\\Documents\\\\Magistrale\\\\TESI\\\\ClusteringAndLinking\\\\aida-yago2-dataset\\\\encodings\\\\AIDA-YAGO2_testa_encodings.jsonl\")\n",
    "path_testb = Path(\n",
    "    \"D:\\\\Sgmon\\\\Documents\\\\Magistrale\\\\TESI\\\\ClusteringAndLinking\\\\aida-yago2-dataset\\\\encodings\\\\AIDA-YAGO2_testb_encodings.jsonl\")\n",
    "raw_encodings_train = open(path_train, 'r').read()\n",
    "raw_encodings_testa = open(path_testa, 'r').read()\n",
    "raw_encodings_testb = open(path_testb, 'r').read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jsonl_parsed_train = [json.loads(x) for x in raw_encodings_train.splitlines()]\n",
    "jsonl_parsed_testa = [json.loads(x) for x in raw_encodings_testa.splitlines()]\n",
    "jsonl_parsed_testb = [json.loads(x) for x in raw_encodings_testb.splitlines()]\n",
    "jsonl_parsed = jsonl_parsed_train + jsonl_parsed_testa + jsonl_parsed_testb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "encodings = [x['encoding'] for x in jsonl_parsed]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "ents_data['encodings'] = encodings\n",
    "ents_data_filtered = ch.filter_data(ents_data, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "ents_data = ents_data_filtered[ents_data_filtered['entities'] != '']\n",
    "entities = ents_data['entities'].values\n",
    "mentions = ents_data['tokens'].values\n",
    "encodings = ents_data['encodings'].values\n",
    "unique_entities = np.unique(entities)\n",
    "gold_standard = Counter(entities)\n",
    "gold_standard = dict(sorted(gold_standard.items(), key=lambda item: item[1], reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "leven_cluster = np.loadtxt(\"../aida-yago2-dataset/db_cluster_levestein_0_3.txt\", dtype=np.int32)\n",
    "lev_cluster_dict = {}\n",
    "for i, x in enumerate(leven_cluster):\n",
    "    try:\n",
    "        lev_cluster_dict[x].append(\n",
    "            (mentions[i], entities[i], encodings[i]))\n",
    "    except:\n",
    "        lev_cluster_dict[x] = [\n",
    "            (mentions[i], entities[i], encodings[i])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2750/2750 [00:02<00:00, 1036.56it/s]\n"
     ]
    }
   ],
   "source": [
    "cluster_all = []\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "clusterizator = AgglomerativeClustering(n_clusters=None, affinity='cosine', distance_threshold=0.035, linkage=\"single\")\n",
    "# clusterizator = DBSCAN(min_samples=0, metric=\"cosine\", n_jobs=-1, eps=0.035)\n",
    "for x in tqdm(lev_cluster_dict):\n",
    "    encodings = [y[2] for y in lev_cluster_dict[x]]\n",
    "    if len(encodings) > 1:\n",
    "        cluster = clusterizator.fit_predict(encodings)\n",
    "        cluster_all.append(cluster)\n",
    "    else:\n",
    "        cluster_all.append(np.zeros(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "clustered_entities = [[row[1] for row in lev_cluster_dict[index]] for index in lev_cluster_dict.keys()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "clusters_splitted = []\n",
    "for n_cluster in range(len(clustered_entities)):\n",
    "    cluster_unique = dict.fromkeys(set(cluster_all[n_cluster]), [])\n",
    "    for key in cluster_unique:\n",
    "        cluster_unique[key] = [clustered_entities[n_cluster][index] for index in\n",
    "                               range(len(clustered_entities[n_cluster])) if cluster_all[n_cluster][index] == key]\n",
    "    clusters_splitted.append(cluster_unique)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "clusters_splitted_dict = []\n",
    "for el in clusters_splitted:\n",
    "    if len(el) == 1:\n",
    "        clusters_splitted_dict.append(el[0])\n",
    "    else:\n",
    "        max_len = max([len(el[key]) for key in el])\n",
    "\n",
    "        indices = [i for i,d in enumerate([len(el[key]) for key in el]) if d==max_len]\n",
    "        for i in indices:\n",
    "            clusters_splitted_dict.append(el[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "clusters_splitted_dict = [dict(Counter(x)) for x in clusters_splitted_dict]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gold standard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "golden_standard_dict = ch.get_gold_standard_dict(ents_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B-CUBED"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2089/2089 [00:01<00:00, 1504.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8922369857472194"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B-cubed - precision\n",
    "bcubed_precision_num = 0\n",
    "for gold_key in tqdm(golden_standard_dict.keys()):\n",
    "    for cluster in clusters_splitted_dict:\n",
    "        try:\n",
    "            bcubed_precision_num = bcubed_precision_num + (pow(cluster[gold_key], 2) /\n",
    "                                                           sum(cluster.values()))\n",
    "        except:\n",
    "            pass\n",
    "bcubed_precision = bcubed_precision_num / sum([sum(x.values()) for x in clusters_splitted_dict])\n",
    "bcubed_precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2089/2089 [00:01<00:00, 1502.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7808019609024331"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B-cubed - recall\n",
    "bcubed_recall_num = 0\n",
    "for gold_key in tqdm(golden_standard_dict.keys()):\n",
    "    for cluster in clusters_splitted_dict:\n",
    "        try:\n",
    "            bcubed_recall_num = bcubed_recall_num + (pow(cluster[gold_key], 2) /\n",
    "                                                     golden_standard_dict[gold_key])\n",
    "        except:\n",
    "            pass\n",
    "bcubed_recall = bcubed_recall_num / ents_data.shape[0]\n",
    "bcubed_recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8328083329514879"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcubed_f1 = (2 * (bcubed_recall * bcubed_precision)) / (\n",
    "        bcubed_precision + bcubed_recall)\n",
    "bcubed_f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### evaluation levestein"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CEAFm precision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2089/2089 [00:01<00:00, 1511.50it/s]\n"
     ]
    }
   ],
   "source": [
    "max_evaluation_dict = dict.fromkeys(set(entities), 0)\n",
    "for key in tqdm(max_evaluation_dict.keys()):\n",
    "    for i in clusters_splitted_dict:\n",
    "        try:\n",
    "            if max_evaluation_dict[key] < i[key]:\n",
    "                max_evaluation_dict[key] = i[key]\n",
    "        except:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8477996701675202"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CEAFm_levenshtein_precision\n",
    "CEAFm_levenshtein_precision = sum([x for x in max_evaluation_dict.values()]) / sum([sum(x.values()) for x in clusters_splitted_dict])\n",
    "CEAFm_levenshtein_precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CEAFm recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8396011518459621"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CEAFm_levenshtein_recall\n",
    "CEAFm_levenshtein_recall = sum([x for x in max_evaluation_dict.values()]) / ents_data.shape[0]\n",
    "CEAFm_levenshtein_recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CEAFm Fscore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8436804940724265"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CEAFm_levenshtein_f1\n",
    "CEAFm_levenshtein_f1 = (2 * (CEAFm_levenshtein_recall * CEAFm_levenshtein_precision)) / (\n",
    "        CEAFm_levenshtein_precision + CEAFm_levenshtein_recall)\n",
    "CEAFm_levenshtein_f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-44a39ab4",
   "language": "python",
   "display_name": "PyCharm (ClusteringAndLinking)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}