{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import getopt\n",
    "import sys\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "import Packages.ClusteringHelper as ch\n",
    "from Packages.TimeEvolving import DataEvolver, compare_ecoding\n",
    "# from textdistance import DamerauLevenshtein, Levenshtein, JaroWinkler\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from Packages.TimeEvolving import Cluster\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from collections import Counter\n",
    "import datetime, time, os\n",
    "from scipy.spatial.distance import cdist\n",
    "from pyxdameraulevenshtein import damerau_levenshtein_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "text, data = ch.read_aida_yago_conll(\n",
    "    \"D:\\\\Sgmon\\\\Documents\\\\Magistrale\\\\TESI\\\\ClusteringAndLinking\\\\aida-yago2-dataset\\\\AIDA-YAGO2-dataset.tsv\")\n",
    "save = False\n",
    "if save:\n",
    "    text_file = open('text.txt', 'w')\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "ents_data = data[data['entities'] != ''].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ents_data = ch.add_entities_embedding(ents_data,\n",
    "                                      \"D:\\\\Sgmon\\\\Documents\\\\Magistrale\\\\TESI\\\\ClusteringAndLinking\\\\aida-yago2-dataset\\\\encodings\")\n",
    "ents_data_filtered = ents_data.copy()\n",
    "documents = set(ents_data.documents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "evolving = DataEvolver(documents, ents_data, randomly=False, step=10)\n",
    "gold_entities = []\n",
    "total_clusters = []\n",
    "n=0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let the cycle start\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/139 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "for iteration in tqdm(evolving, total=math.ceil(len(evolving.documents) / evolving.step)):\n",
    "    current_mentions = list(evolving.get_current_data().mentions)\n",
    "    current_encodings = list(evolving.get_current_data()['encodings'])\n",
    "    current_entities = list(evolving.get_current_data()['entities'])\n",
    "\n",
    "    def dam_lev_metric(x, y):\n",
    "        i, j = x[0], y[0]\n",
    "        if len(i) < 4 or len(j) < 4:\n",
    "            if i == j:\n",
    "                return 0\n",
    "            else:\n",
    "                return damerau_levenshtein_distance(i.lower(), j.lower()) + 3\n",
    "        else:\n",
    "            return damerau_levenshtein_distance(i.lower(), j.lower())\n",
    "\n",
    "    X = np.array(current_mentions).reshape(-1, 1)\n",
    "    m_matrix = cdist(X, X, metric=dam_lev_metric)\n",
    "    clusterizator1 = AgglomerativeClustering(n_clusters=None, affinity='precomputed',\n",
    "                                             distance_threshold=1,\n",
    "                                             linkage=\"single\")\n",
    "    cluster_numbers = clusterizator1.fit_predict(m_matrix)\n",
    "    cee_dict = {k: {'entities': [], 'mentions': [], 'encodings': [], 'sotto_clusters': None} for k in\n",
    "                set(cluster_numbers)}\n",
    "    for i, cluster in enumerate(cluster_numbers):\n",
    "        cee_dict[cluster]['entities'].append(current_entities[i])\n",
    "        cee_dict[cluster]['mentions'].append(current_mentions[i])\n",
    "        cee_dict[cluster]['encodings'].append(current_encodings[i])\n",
    "    cee_list = cee_dict.values()\n",
    "    clusterizator2 = AgglomerativeClustering(n_clusters=None, affinity='cosine', distance_threshold=.03678974213038678,\n",
    "                                             linkage=\"single\")\n",
    "    for cluster in cee_dict.keys():\n",
    "        try:\n",
    "            cee_dict[cluster]['sotto_clusters'] = clusterizator2.fit_predict(cee_dict[cluster]['encodings'])\n",
    "        except ValueError:\n",
    "            cee_dict[cluster]['sotto_clusters'] = np.zeros(1, dtype=np.int8)\n",
    "    sottocluster_list = []\n",
    "    for el in cee_list:\n",
    "        sotto_cluster = {k: Cluster() for k in set(el['sotto_clusters'])}\n",
    "        for i, key in enumerate(el['sotto_clusters']):\n",
    "            sotto_cluster[key].add_element(mention=el['mentions'][i], entity=el['entities'][i],\n",
    "                                           encodings=el['encodings'][i])\n",
    "        sottocluster_list.append(sotto_cluster)\n",
    "    sottocluster_list = [clusters_dict[key] for clusters_dict in sottocluster_list for key in clusters_dict]\n",
    "    current_clusters = total_clusters + sottocluster_list\n",
    "    sotto_encodings = [x.encodings_mean() for x in current_clusters]\n",
    "    clusterizator3 = AgglomerativeClustering(n_clusters=None, affinity='cosine',\n",
    "                                             distance_threshold=.017,\n",
    "                                             linkage=\"single\")\n",
    "    cluster_numbers = clusterizator3.fit_predict(sotto_encodings)\n",
    "    final_clusters = {k: Cluster() for k in set(cluster_numbers)}\n",
    "    last_key = list(set(final_clusters.keys()))[-1]\n",
    "    for i, x in enumerate(current_clusters):\n",
    "        if compare_ecoding(final_clusters[cluster_numbers[i]], x):\n",
    "            final_clusters[cluster_numbers[i]] = final_clusters[cluster_numbers[i]] + x\n",
    "        else:\n",
    "            last_key = last_key + 1\n",
    "            final_clusters[last_key] = x\n",
    "    gold_entities = gold_entities + current_entities\n",
    "    total_clusters = list(final_clusters.values())\n",
    "\n",
    "    broken_cluster = []\n",
    "    to_remove_cluster = []\n",
    "    for cl_index, cl in enumerate(total_clusters):\n",
    "        if len(set([men.lower() for men in cl.mentions])) > 10:\n",
    "            X = np.array(cl.mentions).reshape(-1, 1)\n",
    "            m_matrix = cdist(X, X, metric=dam_lev_metric)\n",
    "            br_clusterizator = AgglomerativeClustering(n_clusters=None, affinity='precomputed',\n",
    "                                         distance_threshold=1,\n",
    "                                         linkage=\"single\")\n",
    "            br_cluster_number = br_clusterizator.fit_predict(cl.mentions)\n",
    "\n",
    "            br_cluster_dict = {k: Cluster() for k in set(br_cluster_number)}\n",
    "            for i, cluster in enumerate(br_cluster_number):\n",
    "                br_cluster_dict[cluster].add_element(cl.mentions[i], cl.entities[i], cl.encodings_list[i])\n",
    "\n",
    "            broken_cluster = broken_cluster + list(br_cluster_dict.values())\n",
    "            to_remove_cluster.append(cl_index)\n",
    "    for i in sorted(to_remove_cluster, reverse=True):\n",
    "        del total_clusters[i]\n",
    "    total_clusters = total_clusters + broken_cluster\n",
    "\n",
    "    # total_clusters = [x for x in total_clusters if len(set([men.lower() for men in x.mentions])) < 15]\n",
    "    # BCUBED\n",
    "    bcubed_precision, bcubed_recall = ch.calcolo_b_cubed(total_clusters, gold_entities)\n",
    "    bcubed_f1 = (2 * (bcubed_recall * bcubed_precision)) / (bcubed_precision + bcubed_recall)\n",
    "    # CEAFm\n",
    "    best_alignment = ch.get_optimal_alignment([x.count_ents() for x in total_clusters], set(gold_entities),\n",
    "                                              is_dict=False)\n",
    "    CEAFm_p = sum(best_alignment.values()) / len(gold_entities)\n",
    "    CEAFm_r = sum(best_alignment.values()) / sum([x.n_elements() for x in total_clusters])\n",
    "    CEAFm_f1 = 2 * (CEAFm_p * CEAFm_r) / (CEAFm_p + CEAFm_r)\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}